# Отчёт по лабораторной работе: применение предобученных моделей (inference-only)

**Дисциплина:** Машинное обучение / Интеллектуальные системы  
**Тема:** Использование предобученных моделей для решения задач NLP, Speech-to-Text, классификации изображений и детекции объектов  
**Язык:** Python 3.10+  
**Режим:** локальный запуск на CPU, без обучения и fine-tuning  

---

## 1. Цель работы
Цель работы — изучить практическое применение современных предобученных моделей и библиотек машинного обучения для решения типовых задач:
- анализ тональности текста (NLP),
- распознавание речи (ASR / Speech-to-Text),
- классификация изображений,
- детекция объектов на изображении (кадр видео).

Дополнительно — освоить принципы локального запуска большой языковой модели (LLM) 7–8B параметров через инструмент Ollama.

**Ключевое ограничение:** использовать только готовые предобученные модели (inference-only), то есть без обучения или дообучения.

---

## 2. Выбранные библиотеки и их преимущества
### 2.1 Hugging Face Transformers
**Преимущества:**
- Единый интерфейс к большому количеству трансформерных моделей для текста, аудио и компьютерного зрения.
- Удобный высокоуровневый API (`pipeline`) для быстрого инференса.
- Автоматическая загрузка весов и токенизаторов из Hugging Face Hub.

В работе Transformers используется для:
- NLP sentiment (модель RuBERT для тональности),
- Speech-to-Text (Whisper),
- Object Detection (DETR).

### 2.2 PyTorch / Torchvision
**Преимущества:**
- Широкое применение в research и production.
- Удобная работа с тензорами, простота инференса.
- Torchvision содержит стандартные модели и предобученные веса для computer vision.

В работе PyTorch/Torchvision используется для классификации изображений через ResNet-50.

---

## 3. Принцип работы моделей
### 3.1 Transformer (NLP и ASR)
Transformer — архитектура на основе механизма внимания (self-attention). В отличие от рекуррентных сетей, Transformer обрабатывает последовательность параллельно, что ускоряет обучение и инференс.

- В задаче **sentiment analysis** Transformer получает токены текста, преобразует их в контекстные представления и на выходе выдаёт вероятности классов тональности.
- В задаче **ASR (Whisper)** Transformer-модель превращает аудиосигнал в последовательность текстовых токенов. Whisper использует encoder-decoder подход: encoder кодирует аудио, decoder генерирует текст.

### 3.2 CNN (ResNet-50 для классификации изображений)
Сверточные нейронные сети (CNN) выделяют локальные признаки (края, текстуры), постепенно формируя более абстрактные представления.

ResNet (Residual Network) добавляет **остаточные (skip) связи**, что:
- упрощает обучение глубоких сетей,
- снижает проблему затухающих градиентов,
- позволяет строить очень глубокие архитектуры.

### 3.3 DETR (Transformer для детекции объектов)
DETR (DEtection TRansformer) использует Transformer для постановки детекции объектов как задачи **предсказания набора объектов**.

Основные идеи:
- CNN backbone извлекает признаки изображения,
- Transformer encoder/decoder обрабатывает признаки,
- на выходе модель предсказывает фиксированное количество «запросов» (object queries), каждый даёт: класс + bbox.

Это упрощает pipeline (нет anchor-box и NMS как в классических детекторах), хотя на практике пороги и фильтрация уверенности всё равно применяются.

---

## 4. Причины выбора моделей
1. **blanchefort/rubert-base-cased-sentiment**
   - Русскоязычная модель, оптимизированная под задачу тональности.
   - Удобно использовать через `transformers.pipeline`.

2. **openai/whisper-small**
   - Один из наиболее популярных open-source подходов к ASR.
   - Хорошо работает на разных языках (включая русский), в т.ч. на CPU (медленнее, но достаточно для демонстрации).

3. **ResNet-50 (torchvision)**
   - Классическая baseline-модель для ImageNet.
   - Поддерживается напрямую Torchvision, легко воспроизводится.

4. **facebook/detr-resnet-50**
   - Современная архитектура детекции на базе Transformer.
   - Доступна в Transformers, совместима с PyTorch.

---

## 5. Датасеты и источники данных (что использовалось при обучении)
### 5.1 NLP: тональность (примерные датасеты)
Для русскоязычных моделей тональности используются наборы вроде:
- RuSentiment,
- другие публичные корпуса отзывов/соцсетей.

В нашей работе модель не обучается, мы лишь делаем инференс на введённом тексте.

### 5.2 ASR: Whisper
Whisper обучался на больших объёмах многозадачных аудиоданных (в т.ч. веб-данные). Конкретный датасет — смесь источников.

### 5.3 Image classification: ImageNet
ResNet-50 обычно публикуется с весами, обученными на ImageNet-1k:
- 1000 классов,
- миллионы размеченных изображений.

### 5.4 Object detection: COCO
DETR ResNet-50 часто публикуется с весами, обученными на MS COCO:
- 80 классов объектов,
- bbox-аннотации.

---

## 6. Метрики качества (теория)
> В этой работе метрики приводятся как стандартные показатели качества для соответствующих задач. При реальном сравнении моделей требуется тестовый датасет.

### 6.1 Accuracy
Доля правильных ответов классификатора:
\[
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\]

### 6.2 F1-score
Гармоническое среднее Precision и Recall:
\[
F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
\]

### 6.3 WER (Word Error Rate)
Метрика качества распознавания речи:
\[
WER = \frac{S + D + I}{N}
\]
где S — substitutions, D — deletions, I — insertions, N — число слов в эталоне.

### 6.4 mAP (mean Average Precision)
Главная метрика для детекции объектов. Вычисляется как среднее значение AP (area under precision-recall curve) по классам и IoU-порогам.

---

## 7. Инфраструктурные метрики
В инференсе важны:
- **время инференса** (latency): среднее/медиана на один запрос,
- **потребление памяти** (RAM),
- (опционально) использование CPU.

В данной работе скрипты выводят примерное время инференса (через `time.perf_counter`). Потребление памяти зависит от ОС и размера модели; для строгих измерений можно использовать `psutil`.

---

## 8. Особенности реализации
1. Все решения построены по принципу «минимальный рабочий пример».
2. По умолчанию выбран CPU:
   - в Transformers не задаётся `device` (или задаётся `device=-1`),
   - в PyTorch модель и тензоры размещаются на CPU.
3. Для воспроизводимости:
   - входные примеры заданы прямо в коде,
   - при отсутствии файлов (картинка/кадр/аудио) скрипты создают или скачивают демо-пример.
4. Обработка видео сведена к обработке **одного кадра** (`frame.jpg`), как требуется в задании.

---

## 9. Результаты (пример)
При запуске скриптов пользователь получает:
- для NLP: метку тональности и уверенность,
- для ASR: распознанный текст,
- для image classification: топ-5 классов ImageNet,
- для DETR: список найденных объектов + сохранённое изображение с bbox.

---

## 10. Вывод
В ходе работы были реализованы 4 задачи машинного обучения на основе предобученных моделей без обучения. Показано, что современные экосистемы Hugging Face и PyTorch позволяют быстро получать качественный результат на типовых задачах при минимальном количестве кода.

Дополнительно рассмотрен практический способ локального запуска LLM 7B параметров через Ollama.

